{
    "Experiment": {
        "Observer": {
            "ModuleName": "NearestAgentsObserver",
            "Config": {}
        },
        "Evaluator": {
            "ModuleName": "GoalReached",
            "Config": {}
        },
        "Runtime": {
            "ModuleName": "SingleAgentRuntime",
            "Config": {}
        },
        "Runner": {
            "ModuleName": "SACRunner",
            "Config": {}
        },
        "Agent": {
            "ModuleName": "BehaviorSACAgent",
            "Config": {}
        },
        "Blueprint": {
            "ModuleName": "ContinuousMergingBlueprint",
            "Config": {
                "num_scenarios": 10000,
                "viewer": true
            }
        },
        "NumEvaluationEpisodes": 500,
        "NumVisualizationEpisodes": 10
    },
    "Visualization": {
        "Agents": {
            "Color": {
                "Other": {
                    "Lines": [
                        0.7,
                        0.7,
                        0.7
                    ],
                    "Face": [
                        0.7,
                        0.7,
                        0.7
                    ]
                },
                "Controlled": {
                    "Lines": [
                        0.0,
                        0.27,
                        0.58
                    ],
                    "Face": [
                        0.49,
                        0.63,
                        0.83
                    ]
                },
                "UseColormapForOtherAgents": false,
                "IfColormapUseLineColorOthers": true
            },
            "Alpha": {
                "Controlled": 1.0,
                "Other": 1
            },
            "ColorRoute": [
                0.2,
                0.2,
                0.2
            ],
            "DrawRoute": false,
            "DrawAgentId": true,
            "DrawEvalGoals": true,
            "EvalGoalColor": [
                0.49,
                0.63,
                0.83
            ],
            "DrawHistory": false,
            "DrawHistoryDrawFace": true
        },
        "Map": {
            "XodrLanes": {
                "Boundaries": {
                    "Color": [
                        0.7,
                        0.7,
                        0.7
                    ],
                    "Alpha": 1.0,
                    "Linewidth": 1.0
                }
            },
            "Plane": {
                "Color": [
                    1,
                    1,
                    1,
                    1
                ],
                "Alpha": 1.0
            }
        },
        "Evaluation": {
            "DrawLTLDebugInfo": false
        }
    },
    "ML": {
        "BehaviorTFAAgents": {
            "CheckpointPath": "experiments/runs/highway_nn_small/ckpts/",
            "NumCheckpointsToKeep": 3
        },
        "TFARunner": {
            "SummaryPath": "experiments/runs/highway_nn_small/summ/",
            "EvaluationSteps": 25,
            "InitialCollectionEpisodes": 50,
            "CollectionEpisodesPerStep": 1
        },
        "GoalReachedEvaluator": {
            "GoalReward": 1.0,
            "CollisionPenalty": -1.0,
            "MaxSteps": 60
        },
        "NearestObserver": {
            "NNearestAgents": 5,
            "MinVel": 0.0,
            "MaxVel": 50.0,
            "MaxDist": 75.0,
            "StateSize": 4
        },
        "BehaviorContinuousML": {
            "ActionsLowerBound": [
                -5.0,
                -0.2
            ],
            "ActionsUpperBound": [
                4.0,
                0.2
            ]
        },
        "StateObserver": {
            "VelocityRange": [
                0,
                100
            ],
            "ThetaRange": [
                0,
                6.283185307179586
            ],
            "NormalizationEnabled": true,
            "MaxNumAgents": 2
        },
        "BehaviorSACAgent": {
            "ActorFcLayerParams": [
                512,
                256,
                256
            ],
            "CriticJointFcLayerParams": [
                512,
                256,
                256
            ],
            "ActorLearningRate": 0.0003,
            "CriticLearningRate": 0.0003,
            "AlphaLearningRate": 0.0003,
            "TargetUpdateTau": 0.05,
            "TargetUpdatePeriod": 3,
            "Gamma": 0.995,
            "RewardScaleFactor": 1.0,
            "AgentName": "sac_agent",
            "DebugSummaries": false,
            "ReplayBufferCapacity": 10000,
            "ParallelBufferCalls": 1,
            "BatchSize": 512,
            "BufferNumSteps": 2,
            "BufferPrefetch": 3
        },
        "SACRunner": {
            "NumberOfCollections": 40000,
            "EvaluateEveryNSteps": 250
        },
        "GoalReachedGuiding": {
            "GoalReward": 1.0,
            "CollisionPenalty": -1.0,
            "MaxSteps": 50,
            "ActionPenalty": 0.01,
            "GoalDistance": 0.01
        },
        "NearestAgentsObserver": {
            "MaxOtherDistance": 100
        }
    },
    "BehaviorDynamicModel": {
        "IntegrationTimeDelta": 0.05000000074505806
    },
    "EmbeddingSize": 128,
    "DropoutRate": 0.0,
    "BehaviorIDMClassic": {
        "DesiredVelocity": 30.0,
        "MinimumSpacing": 2.0,
        "DesiredTimeHeadway": 1.5,
        "MaxAcceleration": 1.7000000476837158,
        "AccelerationLowerBound": -5.0,
        "AccelerationUpperBound": 8.0,
        "ComfortableBrakingAcceleration": 1.6699999570846558,
        "MinVelocity": 0.0,
        "MaxVelocity": 50.0,
        "Exponent": 4,
        "BrakeForLaneEnd": false,
        "BrakeForLaneEndEnabledDistance": 60.0,
        "BrakeForLaneEndDistanceOffset": 15.0,
        "NumTrajectoryTimePoints": 11,
        "CoolnessFactor": 0.0
    },
    "World": {
        "remove_agents_out_of_map": false
    },
    "DynamicModel": {
        "wheel_base": 2.700000047683716,
        "delta_max": 0.20000000298023224,
        "lat_acc_max": 4.0,
        "lon_acceleration_max": 4.0,
        "lon_acceleration_min": -8.0
    },
    "agent": {
        "MaxHistoryLength": 50
    },
    "ActorFcLayerParams": [
        512,
        256,
        256
    ],
    "CriticJointFcLayerParams": [
        512,
        256,
        256
    ],
    "ActorLearningRate": 0.0003,
    "CriticLearningRate": 0.0003,
    "AlphaLearningRate": 0.0003,
    "TargetUpdateTau": 0.05,
    "TargetUpdatePeriod": 3,
    "Gamma": 0.995,
    "RewardScaleFactor": 1.0,
    "AgentName": "sac_agent",
    "DebugSummaries": false,
    "ReplayBufferCapacity": 10000,
    "ParallelBufferCalls": 1,
    "BatchSize": 512,
    "BufferNumSteps": 2,
    "BufferPrefetch": 3
}