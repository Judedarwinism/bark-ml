{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Group 1 in Practical Planning Robust Behavior for autonomous driving\n",
    "# Reinforcement Learning using Graph Neural Networks\n",
    "\n",
    "### Tom DÃ¶rr, Marco Oliva, Quoc Trung Nguyen, Silvan Wimmer\n",
    "\n",
    "__Objective__: Implement an reinforcement learning (RL) approach to train a graph neural network (GNN) in the setting of autonomous driving.\n",
    "## Chapter 0: Setting up\n",
    "### 0.0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib as mpl\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "#import json\n",
    "#import pickle\n",
    "#import logging\n",
    "from collections import OrderedDict\n",
    "from matplotlib.patches import Ellipse\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BARK imports\n",
    "from bark.runtime.commons.parameters import ParameterServer\n",
    "from bark.runtime.viewer.matplotlib_viewer import MPViewer\n",
    "from bark.runtime.viewer.video_renderer import VideoRenderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BARK-ML imports\n",
    "from bark_ml.environments.blueprints import ContinuousHighwayBlueprint, \\\n",
    "  ContinuousMergingBlueprint, ContinuousIntersectionBlueprint\n",
    "from bark_ml.environments.single_agent_runtime import SingleAgentRuntime\n",
    "from bark_ml.library_wrappers.lib_tf_agents.agents import BehaviorSACAgent, BehaviorPPOAgent, BehaviorGraphSACAgent\n",
    "#from bark_ml.library_wrappers.lib_tf_agents.runners import SACRunner, PPORunner\n",
    "from bark_ml.observers.graph_observer import GraphObserver\n",
    "#from bark_ml.library_wrappers.lib_tf2_gnn import GNNActorNetwork, GNNCriticNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised_learning.data_generation import DataGenerator\n",
    "from supervised_learning.data_handler import Dataset\n",
    "from supervised_learning.learner import Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1: Local variables for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_ref_highway = OrderedDict([('x', [5112.68310546875, 5119.88330078125]),\n",
    "                                         ('y', [5054.984375, 5304.984375]),\n",
    "                                         ('theta', [0, 6.283185307179586]),\n",
    "                                         ('vel', [0, 100]),\n",
    "                                         ('distance', [0, 250.10366413257154]),\n",
    "                                         ('dx', [-7.2001953125, 7.2001953125]),\n",
    "                                         ('dy', [-250.0, 250.0])])\n",
    "\n",
    "params_path = os.path.join(\"data\", \"tfa_params.json\")\n",
    "params = ParameterServer(filename=params_path)\n",
    "params[\"World\"][\"remove_agents_out_of_map\"] = False\n",
    "data_path = os.path.join(\"data\")\n",
    "\n",
    "visible_distance = params[\"ML\"][\"GraphObserver\"][\"VisibilityRadius\", \"\", 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bark_path = os.path.join(\"/home\", \"silvan\", \"working_bark\")\n",
    "bark_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2: Local functions (will be transfered to helper_functions.py, but easier prototyping here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs.report.helper_functions import visualize_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Reinforcement learning setting\n",
    "- what learning setting we have (observation, action, reward)\n",
    "- SAC approach with actor net outputting distributions of actions and critic net\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_generator = DataGenerator(num_scenarios=3, dump_dir=data_path, params=params)\n",
    "print('Observation space has shape {} \\nwith minimum value \\n{} \\nand maximum value \\n{}'.format(graph_generator.env.observation_space.shape, graph_generator.env.observation_space.low, graph_generator.env.observation_space.high))\n",
    "print('Action space has shape {}\\n with minimum value \\n{}\\nand maximum value \\n{}'.format(graph_generator.env.action_space.shape, graph_generator.env.action_space.low, graph_generator.env.action_space.high))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the reinforcement learning problem, the observation of environment has size of **3**+**agent_limit** x **feature_len** + size(**adjacency_matrix**), in which: \n",
    "- **agent_limit** is the maximum number of agents that can be observed\n",
    "- **feature_len** is number feature per agent \n",
    "- **adjacency_matrix** represent relation between one agent with other agents, which has size **agent_limit** x **agent_limit** \n",
    "- the first three components are maximum number of agents, actual number of agents and number of feature per agent\n",
    "\n",
    "In this case, **agent_limmit** = 12 and **feature_len** = 11\n",
    "\n",
    "The action has size of 2, which represent the steering and acceleration of agent, respectively\n",
    "\n",
    "The reward is assigned as follows: \n",
    " - If the agent reaches goal, it receives reward of 1\n",
    " - If the agent crashes, it receives reward of -1\n",
    " - For each time step that the agent does not crash, it receives a reward of 0.01\n",
    " \n",
    "Our project implements the Soft Actor Critic algorithm for solving the reinforement learning problem. It consists of two different network: \n",
    "  - The **Critic network** receives observation and action as inputs and tries to approximate the action-value function $Q_{\\phi_i}(s,a)$ to the true action-value function $Q^{\\pi}(s,a)$. More specifically, it tries to minimize the error between approximated and target value function\n",
    "  \\begin{equation}\n",
    "  L(\\phi_i, {\\mathcal D}) = \\underset{(s,a,r,s',d) \\sim {\\mathcal D}}{{\\mathrm E}}\\left[\n",
    "    \\Bigg( Q_{\\phi_i}(s,a) - y(r,s',d) \\Bigg)^2\n",
    "    \\right]\n",
    "  \\end{equation}\n",
    "\n",
    "    \n",
    "    \n",
    "    where the target is given by \n",
    "   \\begin{equation}\n",
    "    y(r, s', d) = r + \\gamma (1 - d) \\left( \\min_{j=1,2} Q_{\\phi_{\\text{targ},j}}(s', \\tilde{a}') - \\alpha \\log \\pi_{\\theta}(\\tilde{a}'|s') \\right), \\;\\;\\;\\;\\; \\tilde{a}' \\sim \\pi_{\\theta}(\\cdot|s')\n",
    "   \\end{equation}\n",
    "\n",
    "    \n",
    "  - The **Actor network** receives observation as inputs and tries to predict the optimal action, which maximize the expected future return plus expected future entropy\n",
    "  \\begin{split}\n",
    "V^{\\pi}(s)&= E_{a \\sim \\pi}[{Q^{\\pi}(s,a)} + \\alpha H\\left(\\pi(\\cdot|s)\\right)] \\\\\n",
    " &= E_{a \\sim \\pi}[{Q^{\\pi}(s,a) - \\alpha \\log \\pi(a|s)}]\n",
    "\\end{split}\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Observervation of graph data - GraphObserver\n",
    "- generate some dummy data to show graph observation\n",
    "- explain a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_data = graph_generator.run_scenarios()\n",
    "# Window popping up due to MPViewer of BARK lib - not our fault!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random data_point from data_set\n",
    "data_point = random.choice(random.choice(scenario_data))\n",
    "observation = data_point[\"graph\"]\n",
    "graph = GraphObserver.graph_from_observation(observation)\n",
    "\n",
    "# Visualize datapoint (graph data)\n",
    "fig = plt.figure(figsize=(4,9))\n",
    "ax  = fig.add_subplot(111)\n",
    "ax.set_xlim(-1,1)\n",
    "ax.set_ylim(-1,1)\n",
    "visualize_graph(data_point, ax, visible_distance, normalization_ref_highway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image from above shows the perceived environment from the agent's perspective in graph structure:\n",
    "- the red node is the $\\color{red}{\\text{controlled/ego agent}}$\n",
    "- the blue agents are $\\color{blue}{\\text{other agents which are not controlled}}$\n",
    "- the yellow zone indicates the <mark>area that agents are visible to the ego agent<mark>. Visibility is further indicated by the missing connections to agents outside the zone\n",
    "- the green point shows the $\\color{green}{\\text{goal of the ego agent}}$\n",
    "\n",
    "About every other agent that the ego agent is perceiving (and about itself) the following information are represented in the individual node features:\n",
    "- Position -> $x$ and $y$-Coordinates\n",
    "- Orientation -> $\\theta$\n",
    "- Velocity -> $v$\n",
    "- Information related to the goal:\n",
    "    - Position of goal -> $x_{goal}$ and $y_{goal}$-Coordinates\n",
    "    - Distance to goal -> $dx$ and $dy$ and $d=\\sqrt {dxÂ²+dyÂ²}$\n",
    "    - Necessary orientation at goal position -> $\\theta_{goal}$\n",
    "    - Necessary velocity at goal position -> $v_{goal}$\n",
    "    \n",
    "The following cell shows the keys under which the node_features are accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = graph.nodes[1].keys()\n",
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into how we apply graph neural networks to our problem, let's have a **very brief** overview about the idea behind them.  \n",
    "Most importantly, they operate on graph structured data, i.e. data consisting of \n",
    "- **Nodes:** feature vectors (node embeddings) of some data entities (and optionally a label), in our case each vehicle is a node\n",
    "- **Edges:** specified links between nodes\n",
    "- **Edge features:** optionally, each link between nodes can have its own feature vector\n",
    "\n",
    "In the section about the `GraphObserver` above, we've already seen how this graph can look like in our scenario. Let's take a step back and use a simplified visualization where the green node represents the ego vehicle and the remaining nodes are other vehicles in its vecinity on the road.\n",
    "\n",
    "![Schematic view of a GNN](images/simple_gnn.png)\n",
    "\n",
    "The ego node is connected to both other nodes (it \"sees\" the other nodes) which in turn do not see each other.\n",
    "\n",
    "Now, the nodes send messages (their current embeddings) along all outgoing links (here, all links are bidrectional), propagated through a neural network. From now on, we refer to this neural network as the _message passing layer(s)_.\n",
    "\n",
    "> **NOTE**  \n",
    "All edges share the same neural network, instead of each edge having its own weights.\n",
    "\n",
    "Each node aggregates all incoming messages using an aggregation function, like summing or averaging. The result is then processed by another neural network, e.g. a recurrent unit, which computes the new embedding of the node.\n",
    "\n",
    "\n",
    "In our project, we have integrated two different libraries that offer GNN implementations:\n",
    "1. [tf2_gnn](https://github.com/microsoft/tf2-gnn): the library that was initially planned to be used in the project\n",
    "2. [Spektral](https://graphneural.network/#installation): a library that supports edge features, which `tf2_gnn` does not\n",
    "\n",
    "In summary, the node embeddings are updated as follows (exemplary):\n",
    "\n",
    "```python\n",
    "embeddings = recurrent_unit(embeddings, sum(edge_mlp(neighbor_embeddings)))\n",
    "```\n",
    "or\n",
    "\n",
    "$$h_{i,t} = \\mathrm{g} \\big(h_{i, t-1}, \\sum^{N_{i, t}}_j \\mathrm{f}(n_{j,t-1}) \\big)$$ where $h_{i,t}$ is the embedding of node $i$ at time $t$, $\\mathrm{g}$ may be a gated recurrent unit at the nodes, $N_{i, t}$ is the number of neighbors (incoming edges) of node $i$ at time $t$, $n_j$ are the neighbors and $\\mathrm{f}$ is a simple feed-forward neural network on the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: The `GNNWrapper` class\n",
    "\n",
    "As an abstraction over the specific implementation of the graph neural network, we implemented a wrapper class called `GNNWrapper`. Its primary function is to act just as a GNN and so the only interface is the `call` function that accepts a batch of observations (array representations of graphs) and returns a batch of updated node embeddings for each graph.\n",
    "\n",
    "In order to support `tf2_gnn` and `Spektral`, we have two distinct call implementations, one for each library. The `GNNWrapper` class decides which one to call based on the arguments given in the initialization.\n",
    "\n",
    "Both functions however work almost the same:\n",
    "1. Convert the given observations into nodes, edges and, when using `Spektral`, edges features.\n",
    "2. Call the respective library with the converted graph representation.\n",
    "\n",
    "When specifying `Spektral` as the GNN library, the call function looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building with input shape (2, 5, 5, 4)\n",
      "building with input shape (2, 5, 5, 128)\n",
      "building with input shape (2, 5, 16)\n",
      "Here's how the embeddings of the ego agent have changed:\n",
      "\n",
      "old embeddings of shape (5,): \n",
      "[0.18865514 0.01158873 0.98427624 0.7576805  0.80028915]\n",
      "\n",
      "new embeddings of shape (16,): \n",
      "[0.         0.         0.         0.88966125 0.08920783 0.\n",
      " 0.         0.67161393 0.03574216 0.         0.         0.\n",
      " 0.         0.         0.16259304 0.09131021]\n"
     ]
    }
   ],
   "source": [
    "from spektral.layers import EdgeConditionedConv, GlobalAttnSumPool\n",
    "from tensorflow.keras.layers import Dense\n",
    "from bark_ml.observers.graph_observer import GraphObserver\n",
    "from docs.report.helper_functions import get_sample_observations, graph_dims\n",
    "\n",
    "def call_spektral_demo(observations):\n",
    "    # define the layers of the GNN (normally, this happens in the __init__ function)\n",
    "    edge_convolution = EdgeConditionedConv(channels=16, kernel_network=[128], activation=\"relu\")\n",
    "    dense = Dense(units=256, activation=\"tanh\")\n",
    "\n",
    "    def call_spektral(observations, training=False):\n",
    "        # convert the observations into\n",
    "        # old_embeddings: tensor containing the node features (embeddings)\n",
    "        # A: binary adjacency matrix specifying edges in the graph\n",
    "        # E: tensor containg edge features\n",
    "        old_embeddings, A, E = GraphObserver.graph(observations, graph_dims)\n",
    "\n",
    "        # pass the inputs through an edge conditioned convolution\n",
    "        # layer and receive new node embeddings\n",
    "        new_embeddings = edge_convolution([old_embeddings, A, E])\n",
    "        \n",
    "        # pass the new node embeddings through a dense layer\n",
    "        X = dense(new_embeddings)\n",
    "\n",
    "        # output the final transformed node embeddings\n",
    "        return old_embeddings, new_embeddings\n",
    "    \n",
    "    old_embeddings, new_embeddings = call_spektral(observations)\n",
    "    \n",
    "    print(\"Here's how the embeddings of the ego agent have changed:\\n\")\n",
    "    print(f'old embeddings of shape {old_embeddings[0, 0].shape}: \\n{old_embeddings[0,0,:].numpy()}\\n')\n",
    "    print(f'new embeddings of shape {new_embeddings[0, 0].shape}: \\n{new_embeddings[0,0,:].numpy()}')\n",
    "\n",
    "# uncomment the following line to call the function with sample observations\n",
    "call_spektral_demo(get_sample_observations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison, when `tf2_gnn` is specified, the implementation looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2_gnn.layers import GNN, GNNInput\n",
    "import pprint as pp\n",
    "import tensorflow as tf\n",
    "\n",
    "def call_tf2_gnn_demo(observations):\n",
    "    # the number and types of layers in the GNN are all encoded\n",
    "    # in the parameters dictionary\n",
    "    gnn_params = GNN.get_default_hyperparameters()\n",
    "\n",
    "    # uncomment the following two lines to have a look at them\n",
    "    #print(f'GNN parameters:')\n",
    "    #pp.pprint(gnn_params)\n",
    "\n",
    "    # initialize a GNN instance which acts as a keras layer\n",
    "    gnn = GNN(gnn_params)\n",
    "\n",
    "    def call_tf2_gnn(observations, training=False):\n",
    "        batch_size = tf.constant(observations.shape[0])\n",
    "\n",
    "        # convert the observations into\n",
    "        # old_embeddings: tensor containing the node features\n",
    "        # A: dense adjacency list in the format [[0, 1], [2, 4]]\n",
    "        #    specifying source and target node ids of an egde\n",
    "        # node_to_graph_map: a tensor that assigns each node in X to a graph\n",
    "        old_embeddings, A, node_to_graph_map = GraphObserver.graph(\n",
    "          observations,\n",
    "          graph_dims=graph_dims, \n",
    "          dense=True)\n",
    "        \n",
    "        # build the struct that tf2_gnn expects as input\n",
    "        gnn_input = GNNInput(\n",
    "          node_features=old_embeddings,\n",
    "          adjacency_lists=(A,),\n",
    "          node_to_graph_map=node_to_graph_map,\n",
    "          num_graphs=batch_size,\n",
    "        )\n",
    "\n",
    "        new_embeddings = gnn(gnn_input, training=training)\n",
    "        \n",
    "        # only for demo purposes\n",
    "        old_embeddings = tf.reshape(old_embeddings, [batch_size, graph_dims[0], -1])\n",
    "        new_embeddings = tf.reshape(new_embeddings, [batch_size, 5, -1])\n",
    "        \n",
    "        return old_embeddings, new_embeddings\n",
    "    \n",
    "    old_embeddings, new_embeddings = call_tf2_gnn(observations)\n",
    "    \n",
    "    print(\"\\nHere's how the embeddings of the ego agent have changed:\\n\")\n",
    "    print(f'old embeddings of shape {old_embeddings[0, 0].shape}: \\n{old_embeddings[0,0,:].numpy()}\\n')\n",
    "    print(f'new embeddings of shape {new_embeddings[0, 0].shape}: \\n{new_embeddings[0,0,:].numpy()}')\n",
    "\n",
    "# uncomment the following line to call the function with sample observations\n",
    "#call_tf2_gnn_demo(get_sample_observations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the GNN functionality nicely abstracted behind this wrapper, we can now easily integrate it into the Soft-Actor-Critic framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: The Soft-Actor-Critic Algorithm with Graph Neural Networks\n",
    "\n",
    "Next, let's examine the integrated system.\n",
    "\n",
    "Above, we have already discussed how the **Soft-Actor-Critic** algorithm works on a high level and how the SAC-agent is integrated into **BARK-ML**. In our case, we want to exploit the graph-like structure of traffic scenarios and have already encoded the state of the world as a graph. Now, we want to apply graph neural networks to the SAC algorithm. \n",
    "\n",
    "The resulting actor and critic networks are quite similar in structure. Here's how they work and what they compute.\n",
    "\n",
    "### The Actor Network\n",
    "\n",
    "**Input**: a batch of observations of shape _(batch_size, observation_size)_  \n",
    "**Output**: a batch of a normal distributions over the action space from which the policy will sample the actions performed by the agent\n",
    "\n",
    "![Actor Network Architecture](images/actor_architecture.png)\n",
    "\n",
    "**1. GNN**  \n",
    "The observations are directly fed into the graph neural network (a `GNNWrapper` instance). It converts the observations into graphs and computes new node embeddings for each graph by means of message passing and aggregation. Depending on which GNN library is selected, these embeddings are flattened with a either a pooling (`spektral`) or a global exchange (`tf2_gnn`) layer and finally propagated through a dense layer that outputs flattened graph representations.\n",
    "\n",
    "> **NOTE**  \n",
    "From here on, we're only interested in the embeddings of the ego agent. Hence, instead of feeding the whole graph representation into the encoding network, we extract the embeddings of the first node of each graph, which represents the ego agent.\n",
    "\n",
    "**2. Encoding Network**  \n",
    "In the encoding network, the node embeddings of the ego agent are now passed through a series of dense layers. Depending on the parameters passed into the actor, we can also add convolutions, dropout and other types of layers here.\n",
    "\n",
    "**3. Projection Network**  \n",
    "Finally, the projection network receives the hidden representations after the encoding network and computes a normal distribution over the action space for each observation contained in the batch, modeled by a mean and a standard deviation.\n",
    "\n",
    "In a very simplified manner for brevity, the implementation of the actor's `call` function looks as follows:\n",
    "```python\n",
    "def call(self, observations, training=False):\n",
    "    batch_size, feature_len = observations.shape\n",
    "    \n",
    "    # get the updated node embeddings\n",
    "    output = self._gnn(observations, training=training)\n",
    "\n",
    "    # extract the ego state (the first node embedding vector of each batch element)\n",
    "    output = output[:, 0]\n",
    "    \n",
    "    # pass the ego agent's node embeddings through the encoder\n",
    "    output = self._encoder(output, training=training)\n",
    "    \n",
    "    # compute a normal distribution\n",
    "    output = self._projection_net(output, training=training)\n",
    "\n",
    "    return output\n",
    "```\n",
    "\n",
    "### The Critic Network\n",
    "\n",
    "**Input**: a batch of observation-action pairs, i.e. `[obs, action]` with shapes _(batch_size, observation_size)_ and _(batch_size, 2)_  \n",
    "**Output**: a scalar value assigned to each observation-action pair\n",
    "\n",
    "![Critic Network Architecture](images/critic_architecture.png)\n",
    "\n",
    "The major difference compared to the actor network is that in the critic, we have two parallel pipelines for the observations and their corresponding actions.\n",
    "\n",
    "**1. Actions**  \n",
    "The actions are simply passed into an action encoding network that works similar to the encoding network of the actor network, i.e. a series of dense layers with optional convolutions, dropout layers, etc.\n",
    "\n",
    "**2. Observations**  \n",
    "The observations are processed in the exact same way as in the actor network. We compute new graph representations in the GNN, extract the ego node embeddings and pass them through an encoding network.\n",
    "\n",
    "**3. Joining Actions and Observations**  \n",
    "After receiving the outputs from the action and observation encoding networks, we concatenate the observation-action pair of each element in the batch to one feature vector.  \n",
    "Finally, we pass this concatenated state through a fully connected joint network which outputs a scalar value for each observation-action pair.\n",
    "\n",
    "Again, a simplified version of the implemenation looks like this:\n",
    "```python\n",
    "def call(self, inputs, training=False):\n",
    "    observations, actions = inputs\n",
    "    batch_size = observations.shape[0]\n",
    "     \n",
    "    # get the updated node embeddings\n",
    "    node_embeddings = self._gnn.batch_call(observations, training=training)\n",
    "    \n",
    "    # extract the ego state (the first node embedding vector of each batch element)\n",
    "    output = output[:, 0]\n",
    "    \n",
    "    # pass the node embeddings through their observation encoder\n",
    "    node_embeddings = self._observation_encoder(node_embeddings, trainig=training)\n",
    "    \n",
    "    # do the same for the actions with a different action encoder\n",
    "    actions = self._action_encoder(actions, training=training)\n",
    "    \n",
    "    # concatenate observations and actions into one vector\n",
    "    joint = tf.concat([node_embeddings, actions], 1)\n",
    "    \n",
    "    # compute a scalar output value\n",
    "    output = self._joint_net(joint, training=training)\n",
    "\n",
    "    return output, network_state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The following cell sets up an SAC-agent using the graph neural networks described above to be used in BARK-ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco.oliva/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CriticNetwork_GNN with 'tf2_gnn'...\n",
      "Initializing ActorNetwork_GNN with 'tf2_gnn'...\n",
      "[256, 128]\n",
      "building with input shape (0, 129)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 128)\n",
      "Initializing TargetCriticNetwork1_GNN with 'tf2_gnn'...\n",
      "building with input shape (0, 129)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 128)\n",
      "Initializing CriticNetwork2_GNN with 'tf2_gnn'...\n",
      "building with input shape (0, 129)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 128)\n",
      "Initializing TargetCriticNetwork2_GNN with 'tf2_gnn'...\n",
      "building with input shape (0, 129)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 128)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 256)\n",
      "building with input shape (0, 128)\n",
      "building with input shape (0, 128)\n",
      "WARNING:tensorflow:From /Users/marco.oliva/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/distributions/utils.py:92: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No checkpoint available at \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2_gnn/gnn_wrapper.py:72 call  *\n        return self.call_tf2_gnn(observations, training)\n    /Users/marco.oliva/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:568 __call__\n        result = self._call(*args, **kwds)\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2_gnn/gnn_wrapper.py:88 call_tf2_gnn  *\n        X, A, node_to_graph_map = GraphObserver.graph(\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/observers/graph_observer.py:151 graph  *\n        n_nodes, n_features = graph_dims[0:2]\n\n    TypeError: 'NoneType' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9efc454b609e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0manalyse_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-9efc454b609e>\u001b[0m in \u001b[0;36msetup_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBehaviorGraphSACAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprepare_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/docs/report/helper_functions.py\u001b[0m in \u001b[0;36mprepare_agent\u001b[0;34m(agent, params, env)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collection_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, time_step, policy_state, num_episodes, maximum_iterations)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         maximum_iterations=maximum_iterations)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   def _run(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, time_step, policy_state, num_episodes, maximum_iterations)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         name='driver_loop')\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2476\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2712\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2713\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(counter, time_step, policy_state)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mloop_vars\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnext\u001b[0m \u001b[0miteration\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m       \u001b[0maction_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0;31m# TODO(b/134487572): TF2 while_loop seems to either ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automatic_state_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mpolicy_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclip_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36m_action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[1;32m    467\u001b[0m     \u001b[0mseed_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeedStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ppo_policy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     \u001b[0mdistribution_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     actions = tf.nest.map_structure(\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreparameterized_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/policies/actor_policy.py\u001b[0m in \u001b[0;36m_distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Actor network outputs nested structure of distributions or actions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     actions_or_distributions, policy_state = self._apply_actor_network(\n\u001b[0;32m--> 149\u001b[0;31m         network_observation, time_step.step_type, policy_state, mask=mask)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_or_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/policies/actor_policy.py\u001b[0m in \u001b[0;36m_apply_actor_network\u001b[0;34m(self, observation, step_type, policy_state, mask)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       return self._actor_network(\n\u001b[0;32m--> 124\u001b[0;31m           observation, step_type, policy_state, training=self._training)\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       return self._actor_network(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnetwork_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2_gnn/gnn_actor_network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, observations, step_type, network_state, training)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# extract ego state (node 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2_gnn/gnn_wrapper.py:72 call  *\n        return self.call_tf2_gnn(observations, training)\n    /Users/marco.oliva/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:568 __call__\n        result = self._call(*args, **kwds)\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2_gnn/gnn_wrapper.py:88 call_tf2_gnn  *\n        X, A, node_to_graph_map = GraphObserver.graph(\n    /private/var/tmp/_bazel_marco.oliva/818820b99828947bd7cbf1a2080eafc5/execroot/bark_ml/bazel-out/darwin-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/observers/graph_observer.py:151 graph  *\n        n_nodes, n_features = graph_dims[0:2]\n\n    TypeError: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/marco.oliva/.pyenv/versions/3.7-dev/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bark.runtime.commons.parameters import ParameterServer\n",
    "from bark_ml.environments.blueprints import ContinuousHighwayBlueprint\n",
    "from bark_ml.environments.single_agent_runtime import SingleAgentRuntime\n",
    "from bark_ml.library_wrappers.lib_tf_agents.agents import BehaviorGraphSACAgent\n",
    "from bark_ml.observers.graph_observer import GraphObserver\n",
    "from docs.report.helper_functions import prepare_agent, summarize_agent\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def init_agent():\n",
    "    # set up parameters\n",
    "    params = ParameterServer(filename=\"data/tfa_params.json\")\n",
    "    params[\"World\"][\"remove_agents_out_of_map\"] = False\n",
    "    \n",
    "    # create environment\n",
    "    bp = ContinuousHighwayBlueprint(params, number_of_senarios=2500, random_seed=0)\n",
    "    observer = GraphObserver(params=params)\n",
    "    env = SingleAgentRuntime(blueprint=bp, observer=observer, render=False)\n",
    "    \n",
    "    # create agent\n",
    "    agent = BehaviorGraphSACAgent(environment=env, params=params)\n",
    "    prepare_agent(agent, params, env)\n",
    "    \n",
    "    return agent\n",
    "\n",
    "summarize_agent(init_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you feel like experimenting with the agent, execute the following cell to get an overview of the most important parameters you can tweak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs.report.helper_functions import print_parameter_overview\n",
    "#print_parameter_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6: Evaluation of capabilites of actor net\n",
    "- introduce supervised setting\n",
    "- benchmark GNN-SAC vs SAC, randomActor and ConstantActor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apendix: Commands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run bazel commands from here (no visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!cd /home/silvan/working_bark && bazel run //examples:tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/silvan/working_bark && bazel run //examples:tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
